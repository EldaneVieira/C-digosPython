{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EldaneVieira/CodigosPython/blob/main/Localizando_objetos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ15yGqjM1z"
      },
      "source": [
        "# Localizando objeto\n",
        "\n",
        "Este é um exemplo de implementação de rede capaz de localizar um objeto em um plano bidimensional.\n",
        "Foi usada a base dados OpenMoji (https://openmoji.org/) – the open-source emoji and icon project. License: CC BY-SA 4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWHR2O5j2g0"
      },
      "source": [
        "##Download e apresentação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsuZWoD6cvYt"
      },
      "source": [
        "!wget https://github.com/hfg-gmuend/openmoji/releases/latest/download/openmoji-72x72-color.zip\n",
        "!mkdir emojis\n",
        "!unzip -q openmoji-72x72-color.zip -d ./emojis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsBFzZWNxnFN"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout #Import some useful libraries\n",
        "\n",
        "print('Using TensorFlow version', tf.__version__) #Tensorflow version check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_cD7ll7gAnD"
      },
      "source": [
        "emojis = {\n",
        "    0: {'name': 'feliz', 'file': '1F642.png'},\n",
        "    1: {'name': 'rindo', 'file': '1F602.png'},\n",
        "    2: {'name': 'cético', 'file': '1F928.png'},\n",
        "    3: {'name': 'triste', 'file': '1F630.png'},\n",
        "    4: {'name': 'legal', 'file': '1F60E.png'},\n",
        "    5: {'name': 'uau', 'file': '1F62F.png'},\n",
        "    6: {'name': 'chorando', 'file': '1F62D.png'},\n",
        "    7: {'name': 'vomitando', 'file': '1F92E.png'},\n",
        "    8: {'name': 'ansioso', 'file': '1F62C.png'}\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "for i, (j, e) in enumerate(emojis.items()):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(plt.imread(os.path.join('emojis', e['file'])))\n",
        "    plt.xlabel(e['name'])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0gSTjKDkJ9y"
      },
      "source": [
        "## Gerando amostras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn91bMsseWJu"
      },
      "source": [
        "for class_id, values in emojis.items():\n",
        "    png_file = Image.open(os.path.join('emojis', values['file'])).convert('RGBA')\n",
        "    png_file.load()\n",
        "    new_file = Image.new(\"RGB\", png_file.size, (255, 255, 255))\n",
        "    new_file.paste(png_file, mask=png_file.split()[3])\n",
        "    emojis[class_id]['image'] = new_file"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBZgOVsUke6o"
      },
      "source": [
        "def CreateImageExample():\n",
        "  class_id = np.random.randint(0,len(emojis))\n",
        "  image = np.ones(shape=(144,144,3)) * 255\n",
        "  column = np.random.randint(0,72)\n",
        "  row = np.random.randint(0,72)\n",
        "  image[row:row+72, column:column+72,:] = np.array(emojis[class_id]['image'])\n",
        "  return image.astype('uint8'), class_id, (row+10)/144,(column+10)/144"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xz9sL75lFLW"
      },
      "source": [
        "image, class_id, row, col = CreateImageExample()\n",
        "plt.imshow(image);\n",
        "print(row,col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAriAzdGkO49"
      },
      "source": [
        "## Gerando as marcações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSSY93pHm1Z5"
      },
      "source": [
        "def plot_bounding_box(image, gt_coords, pred_coords=[], norm=False):\n",
        "  if norm:\n",
        "    image *= 255.\n",
        "    image = image.astype('uint8')\n",
        "  image = Image.fromarray(image)\n",
        "  draw = ImageDraw.Draw(image)\n",
        "\n",
        "  row, col = gt_coords\n",
        "  row *= 144\n",
        "  col *= 144\n",
        "  draw.rectangle((col, row, col + 52, row + 52), outline='green', width=3) #primeiro par é o topo da esquerda, segundo par extremidade de baixo da direita\n",
        "\n",
        "  if len(pred_coords) == 2:\n",
        "    row, col = pred_coords\n",
        "    row *= 144\n",
        "    col *= 144\n",
        "    draw.rectangle((col, row, col + 52, row + 52), outline='red', width=3)\n",
        "  return image"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01TUfno0mTQv"
      },
      "source": [
        "image = plot_bounding_box(image, gt_coords=[row, col])\n",
        "plt.imshow(image)\n",
        "plt.title(emojis[class_id]['name'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHiS285zkSNK"
      },
      "source": [
        "## Gerador de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR5AYygBqAVH"
      },
      "source": [
        "def data_generator(batch_size=16):\n",
        "  while True:\n",
        "    x_batch = np.zeros((batch_size, 144, 144, 3))\n",
        "    y_batch = np.zeros((batch_size, 9))\n",
        "    bbox_batch = np.zeros((batch_size, 2))\n",
        "\n",
        "    for i in range(0, batch_size):\n",
        "      image, class_id, row, col = CreateImageExample()\n",
        "      x_batch[i] = image / 255.\n",
        "      y_batch[i, class_id] = 1.0                                           #[0, 0, 0, 0, 1, 0, 0, 0, 0] (1 para a classe 5)\n",
        "      bbox_batch[i] = np.array([row, col])\n",
        "    yield {'image': x_batch}, {'class_out': y_batch, 'box_out': bbox_batch}"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY3pM-O5sS0H"
      },
      "source": [
        "example, label = next(data_generator(1))\n",
        "image = example['image'][0]\n",
        "class_id = np.argmax(label['class_out'][0])\n",
        "coords = label['box_out'][0]\n",
        "\n",
        "image = plot_bounding_box(image, coords, norm=True)\n",
        "plt.imshow(image)\n",
        "plt.title(emojis[class_id]['name'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIfAVFDGkVAT"
      },
      "source": [
        "## Definindo o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jahKrZ9yspGi"
      },
      "source": [
        "input_ = Input(shape=(144, 144, 3), name='image')\n",
        "\n",
        "x = input_\n",
        "\n",
        "for i in range(0, 5):\n",
        "  n_filters = 2**(4 + i)\n",
        "  x = Conv2D(n_filters, 3, activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPool2D(2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "class_out = Dense(9, activation='softmax', name='class_out')(x)\n",
        "box_out = Dense(2, name='box_out')(x)\n",
        "\n",
        "model = tf.keras.models.Model(input_, [class_out, box_out])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "287Mj5b8kZ_t"
      },
      "source": [
        "## Gerando métrica customizada - IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "608R_-1V9QCh"
      },
      "source": [
        "class IoU(tf.keras.metrics.Metric):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(IoU, self).__init__(**kwargs)\n",
        "\n",
        "    self.iou = self.add_weight(name='iou', initializer='zeros')\n",
        "    self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
        "    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    def get_box(y):\n",
        "      rows, cols = rows * 144, cols * 144\n",
        "      y1, y2 = rows, rows + 52\n",
        "      x1, x2 = cols, cols + 52\n",
        "      return x1, y1, x2, y2\n",
        "\n",
        "    def get_area(x1, y1, x2, y2):\n",
        "      return tf.math.abs(x2 - x1) * tf.math.abs(y2 - y1)\n",
        "\n",
        "    gt_x1, gt_y1, gt_x2, gt_y2 = get_box(y_true)\n",
        "    p_x1, p_y1, p_x2, p_y2 = get_box(y_pred)\n",
        "\n",
        "    i_x1 = tf.maximum(gt_x1, p_x1)\n",
        "    i_y1 = tf.maximum(gt_y1, p_y1)\n",
        "    i_x2 = tf.minimum(gt_x2, p_x2)\n",
        "    i_y2 = tf.minimum(gt_y2, p_y2)\n",
        "\n",
        "    i_area = get_area(i_x1, i_y1, i_x2, i_y2)\n",
        "    u_area = get_area(gt_x1, gt_y1, gt_x2, gt_y2) + get_area(p_x1, p_y1, p_x2, p_y2) - i_area\n",
        "\n",
        "    iou = tf.math.divide(i_area, u_area)\n",
        "    self.num_ex.assign_add(1)\n",
        "    self.total_iou.assign_add(tf.reduce_mean(iou))\n",
        "    self.iou = tf.math.divide(self.total_iou, self.num_ex)\n",
        "\n",
        "  def result(self):\n",
        "    return self.iou\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.iou = self.add_weight(name='iou', initializer='zeros')\n",
        "    self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
        "    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Qzo_RpNFaM"
      },
      "source": [
        "## Compilando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl4KzYM9NEb4"
      },
      "source": [
        "model.compile(\n",
        "    loss={\n",
        "        'class_out': 'categorical_crossentropy',\n",
        "        'box_out': 'mse'\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics={\n",
        "        'class_out': 'accuracy',\n",
        "        'box_out': IoU(name='iou')\n",
        "    }\n",
        ")"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgorrihHLZox"
      },
      "source": [
        "## Testando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di5DItY5vuu1"
      },
      "source": [
        "def test_model(model, test_datagen):\n",
        "  example, label = next(test_datagen)\n",
        "  x = example['image']\n",
        "  y = label['class_out']\n",
        "  box = label['box_out']\n",
        "\n",
        "  pred_y, pred_box = model.predict(x)\n",
        "\n",
        "  pred_coords = pred_box[0]\n",
        "  gt_coords = box[0]\n",
        "  pred_class = np.argmax(pred_y[0])\n",
        "  image = x[0]\n",
        "\n",
        "  gt = emojis[np.argmax(y[0])]['name']\n",
        "  pred_class_name = emojis[pred_class]['name']\n",
        "\n",
        "  image = plot_bounding_box(image, gt_coords, pred_coords, norm=True)\n",
        "  color = 'green' if gt == pred_class_name else 'red'\n",
        "\n",
        "  plt.imshow(image)\n",
        "  plt.xlabel(f'Pred: {pred_class_name}', color=color)\n",
        "  plt.ylabel(f'GT: {gt}', color=color)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR3C5zQ_LZox"
      },
      "source": [
        "def test(model):                   #a function for show the test result\n",
        "  test_datagen = data_generator(1)\n",
        "\n",
        "  plt.figure(figsize=(16, 4))\n",
        "\n",
        "  for i in range(0, 6):\n",
        "    plt.subplot(1, 6, i + 1)\n",
        "    test_model(model, test_datagen)\n",
        "  plt.show()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9UgYrTILZox"
      },
      "source": [
        "test(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShowTestImages(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs=None):\n",
        "    test(self.model)\n"
      ],
      "metadata": {
        "id": "i4blhrwkqkul"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvaxZOzOkgDN"
      },
      "source": [
        "## Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfMjSE41ugR7"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    lr *= 0.2\n",
        "  return max(lr, 3e-7)\n",
        "\n",
        "\n",
        "Result = model.fit(\n",
        "    data_generator(),\n",
        "    epochs=50,\n",
        "    steps_per_epoch=500,\n",
        "    callbacks=[\n",
        "               ShowTestImages(),\n",
        "               tf.keras.callbacks.EarlyStopping(monitor='box_out_iou', patience=3, mode='max'),\n",
        "               tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRDTeZT_mSAo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}